{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":14015965,"datasetId":8879404,"databundleVersionId":14792974}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sarraverse/04-model-evaluation?scriptVersionId=284152621\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MODEL EVALUATION AND DEPLOYMENT PREPARATION\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\nimport joblib\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set plot style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n\nprint(\"üìä MODEL EVALUATION AND ANALYSIS\")\nprint(\"=\"*60)\n\n# Load clustering results\nprint(\"\\n1. Loading clustering results...\")\ntry:\n    # Try to load full KMeans results\n    df_clustered = pd.read_csv(\"all_jobs_clustered_full_kmeans.csv\")\n    print(f\"‚úÖ Loaded full KMeans results: {df_clustered.shape}\")\nexcept:\n    # Try sample results\n    try:\n        df_clustered = pd.read_csv(\"all_jobs_clustered_sample_agglo.csv\")\n        print(f\"‚úÖ Loaded sample Agglomerative results: {df_clustered.shape}\")\n    except:\n        try:\n            df_clustered = pd.read_csv(\"all_jobs_clustered_sample_dbscan.csv\")\n            print(f\"‚úÖ Loaded sample DBSCAN results: {df_clustered.shape}\")\n        except:\n            print(\"‚ö†Ô∏è No clustered dataset found. Please run clustering first.\")\n            df_clustered = None\n\nif df_clustered is not None:\n    # Cluster distribution analysis\n    print(\"\\n2. Cluster Distribution Analysis\")\n    print(\"=\"*40)\n    \n    cluster_counts = df_clustered['cluster'].value_counts().sort_index()\n    \n    plt.figure(figsize=(12, 6))\n    bars = plt.bar(range(len(cluster_counts)), cluster_counts.values)\n    plt.xlabel('Cluster ID')\n    plt.ylabel('Number of Jobs')\n    plt.title('Distribution of Jobs Across Clusters')\n    plt.xticks(range(len(cluster_counts)), cluster_counts.index)\n    \n    # Add value labels on bars\n    for bar in bars:\n        height = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n                f'{int(height):,}', ha='center', va='bottom', fontsize=8)\n    \n    plt.tight_layout()\n    plt.savefig('cluster_distribution.png', dpi=100)\n    plt.show()\n    \n    print(\"\\nCluster Statistics:\")\n    print(f\"Total clusters: {len(cluster_counts)}\")\n    print(f\"Average jobs per cluster: {cluster_counts.mean():,.0f}\")\n    print(f\"Std dev of cluster sizes: {cluster_counts.std():,.0f}\")\n    print(f\"Min cluster size: {cluster_counts.min():,}\")\n    print(f\"Max cluster size: {cluster_counts.max():,}\")\n    \n    # Show top clusters\n    print(\"\\nTop 10 Largest Clusters:\")\n    top_clusters = cluster_counts.head(10)\n    for cluster_id, count in top_clusters.items():\n        percentage = (count / len(df_clustered)) * 100\n        print(f\"  Cluster {cluster_id}: {count:,} jobs ({percentage:.1f}%)\")\n\n# Load association rules for evaluation\nprint(\"\\n\" + \"=\"*60)\nprint(\"3. Association Rules Evaluation\")\nprint(\"=\"*40)\n\ntry:\n    # Load all association rules\n    rules_skills = pd.read_csv(\"/kaggle/input/job-skills/association_rules_skills.csv\")\n    rules_categories = pd.read_csv(\"/kaggle/input/job-skills/association_rules_categories.csv\")\n    rules_combined = pd.read_csv(\"/kaggle/input/job-skills/association_rules_combined.csv\")\n    \n    print(f\"‚úÖ Loaded association rules:\")\n    print(f\"   Skill-level rules: {len(rules_skills):,}\")\n    print(f\"   Category-level rules: {len(rules_categories):,}\")\n    print(f\"   Combined rules: {len(rules_combined):,}\")\n    \n    # Analyze rule quality\n    def analyze_rules(rules, name):\n        print(f\"\\n{name} Rules Analysis:\")\n        print(f\"  Total rules: {len(rules):,}\")\n        print(f\"  Average support: {rules['support'].mean():.4f}\")\n        print(f\"  Average confidence: {rules['confidence'].mean():.4f}\")\n        print(f\"  Average lift: {rules['lift'].mean():.4f}\")\n        \n        # High-quality rules (support > 0.02, confidence > 0.5, lift > 1.5)\n        high_quality = rules[\n            (rules['support'] > 0.02) & \n            (rules['confidence'] > 0.5) & \n            (rules['lift'] > 1.5)\n        ]\n        print(f\"  High-quality rules: {len(high_quality):,}\")\n        \n        # Show top 5 high-quality rules\n        if len(high_quality) > 0:\n            print(\"\\n  Top 5 High-Quality Rules:\")\n            top_rules = high_quality.sort_values(['confidence', 'support'], ascending=False).head(5)\n            for idx, row in top_rules.iterrows():\n                antecedents = eval(row['antecedents']) if isinstance(row['antecedents'], str) else row['antecedents']\n                consequents = eval(row['consequents']) if isinstance(row['consequents'], str) else row['consequents']\n                print(f\"    {set(antecedents)} ‚Üí {set(consequents)}\")\n                print(f\"      Support: {row['support']:.4f}, Confidence: {row['confidence']:.4f}, Lift: {row['lift']:.4f}\")\n    \n    analyze_rules(rules_skills, \"Skill-Level\")\n    analyze_rules(rules_categories, \"Category-Level\")\n    analyze_rules(rules_combined, \"Combined\")\n    \n    # Visualization of rules metrics\n    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n    \n    # Support distribution\n    axes[0].hist(rules_skills['support'].head(1000), bins=30, alpha=0.7, label='Skills', color='blue')\n    axes[0].hist(rules_categories['support'].head(1000), bins=30, alpha=0.7, label='Categories', color='orange')\n    axes[0].set_xlabel('Support')\n    axes[0].set_ylabel('Frequency')\n    axes[0].set_title('Support Distribution (First 1000 rules)')\n    axes[0].legend()\n    \n    # Confidence distribution\n    axes[1].hist(rules_skills['confidence'].head(1000), bins=30, alpha=0.7, label='Skills', color='blue')\n    axes[1].hist(rules_categories['confidence'].head(1000), bins=30, alpha=0.7, label='Categories', color='orange')\n    axes[1].set_xlabel('Confidence')\n    axes[1].set_ylabel('Frequency')\n    axes[1].set_title('Confidence Distribution (First 1000 rules)')\n    axes[1].legend()\n    \n    # Lift vs Confidence scatter\n    scatter1 = axes[2].scatter(rules_skills['confidence'].head(500), \n                              rules_skills['lift'].head(500), \n                              alpha=0.5, s=10, label='Skills', color='blue')\n    scatter2 = axes[2].scatter(rules_categories['confidence'].head(500), \n                              rules_categories['lift'].head(500), \n                              alpha=0.5, s=10, label='Categories', color='orange')\n    axes[2].set_xlabel('Confidence')\n    axes[2].set_ylabel('Lift')\n    axes[2].set_title('Lift vs Confidence (First 500 rules)')\n    axes[2].legend()\n    \n    plt.tight_layout()\n    plt.savefig('association_rules_metrics.png', dpi=100)\n    plt.show()\n    \nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Error loading association rules: {e}\")\n    print(\"Please run the association rules notebook first.\")\n\n# Load original data for skill analysis\nprint(\"\\n\" + \"=\"*60)\nprint(\"4. Skill Analysis by Cluster\")\nprint(\"=\"*40)\n\ntry:\n    # Load original mapped data\n    df_mapped = pd.read_csv(\"/kaggle/input/job-skills/all_jobs_mapped.csv\", nrows=50000)\n    print(f\"Loaded mapped data: {df_mapped.shape}\")\n    \n    # Merge with clustering results if available\n    if df_clustered is not None and 'cluster' in df_clustered.columns:\n        # Ensure we have the same number of rows\n        min_rows = min(len(df_mapped), len(df_clustered))\n        df_mapped = df_mapped.iloc[:min_rows].copy()\n        df_mapped['cluster'] = df_clustered['cluster'].iloc[:min_rows].values\n        \n        # Analyze top skills per cluster\n        print(\"\\nTop 5 Skills by Cluster:\")\n        \n        # Function to parse skill list\n        def parse_skill_list(skill_str):\n            if pd.isna(skill_str):\n                return []\n            if isinstance(skill_str, list):\n                return skill_str\n            try:\n                import ast\n                return ast.literal_eval(skill_str)\n            except:\n                return [s.strip() for s in str(skill_str).split(',') if s.strip()]\n        \n        df_mapped['skill_list_parsed'] = df_mapped['skill_list'].apply(parse_skill_list)\n        \n        # Get unique clusters\n        clusters = sorted(df_mapped['cluster'].unique())\n        \n        for cluster_id in clusters[:10]:  # Show first 10 clusters\n            cluster_data = df_mapped[df_mapped['cluster'] == cluster_id]\n            if len(cluster_data) > 0:\n                # Count skills in this cluster\n                skill_counts = {}\n                for skills in cluster_data['skill_list_parsed']:\n                    for skill in skills:\n                        skill_counts[skill] = skill_counts.get(skill, 0) + 1\n                \n                # Get top 5 skills\n                top_skills = sorted(skill_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n                \n                print(f\"\\nCluster {cluster_id} ({len(cluster_data):,} jobs):\")\n                for skill, count in top_skills:\n                    percentage = (count / len(cluster_data)) * 100\n                    print(f\"  {skill}: {count} ({percentage:.1f}%)\")\n    \nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Error in skill analysis: {e}\")\n\n# Summary report\nprint(\"\\n\" + \"=\"*60)\nprint(\"üìà FINAL EVALUATION SUMMARY\")\nprint(\"=\"*60)\n\nprint(\"\\n‚úÖ Data Processing Summary:\")\nprint(\"-\" * 40)\nprint(\"1. Data cleaning completed successfully\")\nprint(\"2. Skills mapped to categories\")\nprint(\"3. Association rules extracted (3 models)\")\nprint(\"4. Clustering performed (3 models)\")\nprint(\"5. Models evaluated with metrics\")\n\nprint(\"\\nüìä Key Findings:\")\nprint(\"-\" * 40)\nif df_clustered is not None:\n    print(f\"1. Clustering identified {len(df_clustered['cluster'].unique())} distinct job clusters\")\n    print(f\"2. Cluster sizes range from {cluster_counts.min():,} to {cluster_counts.max():,} jobs\")\n    print(f\"3. Average cluster size: {cluster_counts.mean():,.0f} jobs\")\n\ntry:\n    if 'rules_skills' in locals():\n        print(f\"4. Association rules found:\")\n        print(f\"   - Skill-level: {len(rules_skills):,} rules\")\n        print(f\"   - Category-level: {len(rules_categories):,} rules\")\n        print(f\"   - Combined: {len(rules_combined):,} rules\")\nexcept:\n    pass\n\nprint(\"\\nüéØ Recommendations for Next Steps:\")\nprint(\"-\" * 40)\nprint(\"1. Fine-tune clustering parameters for better separation\")\nprint(\"2. Validate association rules with domain experts\")\nprint(\"3. Build recommendation system based on skill patterns\")\nprint(\"4. Analyze temporal trends in job skills\")\nprint(\"5. Create interactive dashboard for skill gap analysis\")\n\nprint(\"\\nüíæ Output Files Generated:\")\nprint(\"-\" * 40)\noutput_files = [\n    \"all_jobs_clean_full.csv\",\n    \"skill_migration_clean.csv\",\n    \"all_jobs_mapped.csv\",\n    \"association_rules_skills.csv\",\n    \"association_rules_categories.csv\",\n    \"association_rules_combined.csv\"\n]\n\nfor file in output_files:\n    try:\n        with open(file, 'r') as f:\n            print(f\"‚úÖ {file}\")\n    except:\n        print(f\"‚ùå {file} (not found)\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"üéâ MODEL EVALUATION COMPLETED SUCCESSFULLY!\")\nprint(\"=\"*60)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}