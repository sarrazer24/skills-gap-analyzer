{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e100a9d",
   "metadata": {
    "papermill": {
     "duration": 0.004508,
     "end_time": "2025-12-11T07:58:49.386780",
     "exception": false,
     "start_time": "2025-12-11T07:58:49.382272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Improved K-Means Clustering: Skill-Based Feature Engineering\n",
    "## Objective: Generate high-quality job similarity mapping for the Streamlit app\n",
    "\n",
    "This notebook improves clustering by:\n",
    "1. Using **skill-based features** instead of noisy free-text\n",
    "2. Testing multiple K values (20â€“80) with evaluation metrics\n",
    "3. Manually inspecting clusters for semantic coherence\n",
    "4. Implementing post-filtering logic for better \"similar opportunities\"\n",
    "5. Creating a compact mapping file for the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c425ea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:58:49.396308Z",
     "iopub.status.busy": "2025-12-11T07:58:49.395459Z",
     "iopub.status.idle": "2025-12-11T07:58:53.485882Z",
     "shell.execute_reply": "2025-12-11T07:58:53.484526Z"
    },
    "papermill": {
     "duration": 4.097259,
     "end_time": "2025-12-11T07:58:53.487871",
     "exception": false,
     "start_time": "2025-12-11T07:58:49.390612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ“š IMPROVED K-MEANS CLUSTERING FOR SKILL-BASED JOB SIMILARITY\n",
      "================================================================================\n",
      "\n",
      "âœ… All libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from collections import Counter\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# ML and clustering\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ðŸ“š IMPROVED K-MEANS CLUSTERING FOR SKILL-BASED JOB SIMILARITY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nâœ… All libraries loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff0d02b",
   "metadata": {
    "papermill": {
     "duration": 0.003604,
     "end_time": "2025-12-11T07:58:53.495359",
     "exception": false,
     "start_time": "2025-12-11T07:58:53.491755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 1: Load and Explore Skill-Based Features\n",
    "\n",
    "Load the processed jobs file and verify skill_list availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23303f3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:58:53.504679Z",
     "iopub.status.busy": "2025-12-11T07:58:53.503585Z",
     "iopub.status.idle": "2025-12-11T08:02:42.726189Z",
     "shell.execute_reply": "2025-12-11T08:02:42.725023Z"
    },
    "papermill": {
     "duration": 229.229077,
     "end_time": "2025-12-11T08:02:42.727933",
     "exception": false,
     "start_time": "2025-12-11T07:58:53.498856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from: /kaggle/input/job-skills/all_jobs_mapped.csv\n",
      "\n",
      "ðŸ“Š Dataset shape: (2884556, 9)\n",
      "ðŸ“‹ Columns: ['source', 'job_key', 'job_title', 'job_description', 'skills_raw', 'location', 'company', 'skill_list', 'skill_categories']\n",
      "  âœ… job_id\n",
      "  âœ… job_title\n",
      "  âœ… skill_list\n",
      "  âœ… location\n",
      "  âœ… company\n",
      "  âœ… skill_categories\n",
      "\n",
      "ðŸ“ˆ Skill Statistics:\n",
      "  Total jobs: 2884556\n",
      "  Jobs with skills: 2881535\n",
      "  Avg skills per job: 10.4\n",
      "  Max skills in a job: 463\n",
      "\n",
      "ðŸŽ¯ Sample Jobs:\n",
      "\n",
      "  Job: Air Freight Manager in Slough, UK\n",
      "  Location: Slough, England, United Kingdom\n",
      "  Skills (7): ['air freight management', 'import', 'export', 'time management', 'financial management']...\n",
      "\n",
      "  Job: Investment Analyst\n",
      "  Location: Tehran\n",
      "  Skills (1): ['investment management financial analysis risk assessment asset allocation portfolio optimization']...\n",
      "\n",
      "  Job: Supply Chain Manager\n",
      "  Location: Wellington\n",
      "  Skills (1): ['demand forecasting inventory management data analysis sales and operations planning (s&op) erp software proficiency']...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_path = \"/kaggle/input/job-skills/all_jobs_mapped.csv\"\n",
    "print(f\"Loading from: {data_path}\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"\\nðŸ“Š Dataset shape: {df.shape}\")\n",
    "print(f\"ðŸ“‹ Columns: {list(df.columns)}\")\n",
    "\n",
    "# Create a stable job_id alias from job_key (if not already present)\n",
    "if 'job_key' in df.columns and 'job_id' not in df.columns:\n",
    "    df['job_id'] = df['job_key'].astype(str)\n",
    "\n",
    "# Check for required columns\n",
    "required_cols = ['job_id', 'job_title', 'skill_list', 'location', 'company', 'skill_categories']\n",
    "for col in required_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"  âœ… {col}\")\n",
    "    else:\n",
    "        print(f\"  âŒ {col} - MISSING\")\n",
    "\n",
    "# Parse skill_list column\n",
    "def parse_skill_list(x):\n",
    "    \"\"\"Convert skill_list from string representation to actual list.\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    try:\n",
    "        val = ast.literal_eval(str(x))\n",
    "        if isinstance(val, list):\n",
    "            return [str(s).strip().lower() for s in val]\n",
    "    except:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "df['skill_list'] = df['skill_list'].apply(parse_skill_list)\n",
    "\n",
    "# Display stats\n",
    "print(f\"\\nðŸ“ˆ Skill Statistics:\")\n",
    "print(f\"  Total jobs: {len(df)}\")\n",
    "print(f\"  Jobs with skills: {df['skill_list'].apply(len).gt(0).sum()}\")\n",
    "print(f\"  Avg skills per job: {df['skill_list'].apply(len).mean():.1f}\")\n",
    "print(f\"  Max skills in a job: {df['skill_list'].apply(len).max()}\")\n",
    "\n",
    "# Show samples\n",
    "print(f\"\\nðŸŽ¯ Sample Jobs:\")\n",
    "for idx in df.sample(min(3, len(df)), random_state=42).index:\n",
    "    job = df.iloc[idx]\n",
    "    print(f\"\\n  Job: {job['job_title']}\")\n",
    "    print(f\"  Location: {job['location']}\")\n",
    "    print(f\"  Skills ({len(job['skill_list'])}): {job['skill_list'][:5]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a6f4e8",
   "metadata": {
    "papermill": {
     "duration": 0.003972,
     "end_time": "2025-12-11T08:02:42.736060",
     "exception": false,
     "start_time": "2025-12-11T08:02:42.732088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 2: Build Sparse Skill Vector Representation\n",
    "\n",
    "Create a binary skill matrix (1 if skill present, 0 otherwise) using only the most frequent skills to reduce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb15365f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T08:02:42.746311Z",
     "iopub.status.busy": "2025-12-11T08:02:42.745356Z",
     "iopub.status.idle": "2025-12-11T08:03:19.726629Z",
     "shell.execute_reply": "2025-12-11T08:03:19.725488Z"
    },
    "papermill": {
     "duration": 36.988492,
     "end_time": "2025-12-11T08:03:19.728559",
     "exception": false,
     "start_time": "2025-12-11T08:02:42.740067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Skill Vocabulary:\n",
      "  Total unique skills: 2707646\n",
      "  Frequent skills (>= 30 occurrences): 61954\n",
      "  Top 20 skills by frequency:\n",
      "    communication                            367386 jobs\n",
      "    customer service                         275711 jobs\n",
      "    teamwork                                 224816 jobs\n",
      "    communication skills                     194746 jobs\n",
      "    leadership                               185228 jobs\n",
      "    problem solving                          148894 jobs\n",
      "    time management                          141447 jobs\n",
      "    attention to detail                      132686 jobs\n",
      "    problemsolving                           128635 jobs\n",
      "    project management                       121936 jobs\n",
      "    interpersonal skills                     99280 jobs\n",
      "    patient care                             98982 jobs\n",
      "    sales                                    93515 jobs\n",
      "    nursing                                  87518 jobs\n",
      "    collaboration                            86685 jobs\n",
      "    training                                 84641 jobs\n",
      "    data analysis                            82004 jobs\n",
      "    microsoft office suite                   75486 jobs\n",
      "    organizational skills                    74991 jobs\n",
      "    high school diploma                      74355 jobs\n",
      "\n",
      "ðŸ”¨ Building sparse skill matrix (2884556 jobs Ã— 61954 skills)...\n",
      "âœ… Sparse matrix created: shape (2884556, 61954), density 0.01%\n"
     ]
    }
   ],
   "source": [
    "# Build skill vocabulary: only include skills appearing in >= min_freq jobs\n",
    "min_freq = 30  # Adjust based on data size\n",
    "all_skills = Counter()\n",
    "\n",
    "for skills in df['skill_list']:\n",
    "    all_skills.update(skills)\n",
    "\n",
    "# Keep only frequent skills\n",
    "skill_vocab = sorted([skill for skill, count in all_skills.most_common() if count >= min_freq])\n",
    "print(f\"ðŸ“Š Skill Vocabulary:\")\n",
    "print(f\"  Total unique skills: {len(all_skills)}\")\n",
    "print(f\"  Frequent skills (>= {min_freq} occurrences): {len(skill_vocab)}\")\n",
    "print(f\"  Top 20 skills by frequency:\")\n",
    "for skill, count in all_skills.most_common(20):\n",
    "    print(f\"    {skill:40} {count:5} jobs\")\n",
    "\n",
    "# Build binary skill matrix: rows=jobs, cols=skills\n",
    "def build_skill_matrix(df, skill_vocab):\n",
    "    \"\"\"Build sparse binary matrix where X[i,j] = 1 if job i has skill j.\"\"\"\n",
    "    n_jobs = len(df)\n",
    "    n_skills = len(skill_vocab)\n",
    "    skill_to_idx = {skill: idx for idx, skill in enumerate(skill_vocab)}\n",
    "    \n",
    "    print(f\"\\nðŸ”¨ Building sparse skill matrix ({n_jobs} jobs Ã— {n_skills} skills)...\")\n",
    "    \n",
    "    rows, cols, data = [], [], []\n",
    "    \n",
    "    for job_idx, skills in enumerate(df['skill_list']):\n",
    "        for skill in skills:\n",
    "            if skill in skill_to_idx:\n",
    "                rows.append(job_idx)\n",
    "                cols.append(skill_to_idx[skill])\n",
    "                data.append(1)\n",
    "    \n",
    "    X_sparse = csr_matrix((data, (rows, cols)), shape=(n_jobs, n_skills), dtype=np.int8)\n",
    "    \n",
    "    print(f\"âœ… Sparse matrix created: shape {X_sparse.shape}, density {X_sparse.nnz / (n_jobs * n_skills) * 100:.2f}%\")\n",
    "    return X_sparse, skill_vocab\n",
    "\n",
    "X_sparse, skill_vocab = build_skill_matrix(df, skill_vocab)\n",
    "\n",
    "# Keep a copy of the original dataframe for later reference\n",
    "df_original = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba9ffb7",
   "metadata": {
    "papermill": {
     "duration": 0.004268,
     "end_time": "2025-12-11T08:03:19.737175",
     "exception": false,
     "start_time": "2025-12-11T08:03:19.732907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 3: Tune K-Means with Multiple K Values\n",
    "\n",
    "Test K values from 20 to 80 and compute inertia + silhouette scores on a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ee0dcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T08:03:19.747156Z",
     "iopub.status.busy": "2025-12-11T08:03:19.746784Z",
     "iopub.status.idle": "2025-12-11T08:03:57.274697Z",
     "shell.execute_reply": "2025-12-11T08:03:57.273616Z"
    },
    "papermill": {
     "duration": 37.538279,
     "end_time": "2025-12-11T08:03:57.279547",
     "exception": false,
     "start_time": "2025-12-11T08:03:19.741268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ K-MEANS TUNING\n",
      "Testing K values: [20, 40, 60, 80]\n",
      "Using sample of 5000 jobs for silhouette score evaluation\n",
      "\n",
      "Training K-Means with K=20...\n",
      "  âœ… K=20 | Inertia:     23763101 | Silhouette: -0.2560\n",
      "\n",
      "Training K-Means with K=40...\n",
      "  âœ… K=40 | Inertia:     22898509 | Silhouette: -0.1073\n",
      "\n",
      "Training K-Means with K=60...\n",
      "  âœ… K=60 | Inertia:     23602078 | Silhouette: -0.2288\n",
      "\n",
      "Training K-Means with K=80...\n",
      "  âœ… K=80 | Inertia:     22547104 | Silhouette: -0.0247\n",
      "\n",
      "â±ï¸  Tuning completed in 0.6 minutes\n",
      "\n",
      "ðŸ“Š K-Means Tuning Summary:\n",
      " K      Inertia  Silhouette\n",
      "20 2.376310e+07   -0.256014\n",
      "40 2.289851e+07   -0.107254\n",
      "60 2.360208e+07   -0.228800\n",
      "80 2.254710e+07   -0.024728\n"
     ]
    }
   ],
   "source": [
    "# Tune K-Means for multiple K values\n",
    "k_values = [20, 40, 60, 80]\n",
    "tuning_results = []\n",
    "\n",
    "# Use a sample for silhouette scoring (large datasets can be slow)\n",
    "sample_size = min(5000, len(df))\n",
    "sample_indices = np.random.choice(len(df), sample_size, replace=False)\n",
    "X_sample = X_sparse[sample_indices]\n",
    "\n",
    "print(f\"\\nðŸŽ¯ K-MEANS TUNING\")\n",
    "print(f\"Testing K values: {k_values}\")\n",
    "print(f\"Using sample of {sample_size} jobs for silhouette score evaluation\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"Training K-Means with K={k}...\")\n",
    "    \n",
    "    # Train on full dataset\n",
    "    kmeans = MiniBatchKMeans(\n",
    "        n_clusters=k,\n",
    "        batch_size=1000,\n",
    "        random_state=42,\n",
    "        n_init=3,\n",
    "        max_iter=100\n",
    "    )\n",
    "    labels_full = kmeans.fit_predict(X_sparse)\n",
    "    \n",
    "    # Compute metrics\n",
    "    inertia = kmeans.inertia_\n",
    "    silhouette = silhouette_score(X_sample, kmeans.predict(X_sample), sample_size=1000)\n",
    "    \n",
    "    # Store results\n",
    "    tuning_results.append({\n",
    "        'K': k,\n",
    "        'Inertia': inertia,\n",
    "        'Silhouette': silhouette,\n",
    "        'Model': kmeans,\n",
    "        'Labels': labels_full\n",
    "    })\n",
    "    \n",
    "    print(f\"  âœ… K={k:2d} | Inertia: {inertia:12.0f} | Silhouette: {silhouette:.4f}\\n\")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"â±ï¸  Tuning completed in {elapsed/60:.1f} minutes\")\n",
    "\n",
    "# Convert to DataFrame for easy comparison\n",
    "tuning_df = pd.DataFrame(tuning_results)\n",
    "print(\"\\nðŸ“Š K-Means Tuning Summary:\")\n",
    "print(tuning_df[['K', 'Inertia', 'Silhouette']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f4391b",
   "metadata": {
    "papermill": {
     "duration": 0.004269,
     "end_time": "2025-12-11T08:03:57.288272",
     "exception": false,
     "start_time": "2025-12-11T08:03:57.284003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 4: Evaluate Clusters with Inertia and Silhouette Score\n",
    "\n",
    "Visualize and select the optimal K based on metrics and manual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "197f4f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T08:03:57.299152Z",
     "iopub.status.busy": "2025-12-11T08:03:57.298734Z",
     "iopub.status.idle": "2025-12-11T08:03:57.313214Z",
     "shell.execute_reply": "2025-12-11T08:03:57.312315Z"
    },
    "papermill": {
     "duration": 0.021905,
     "end_time": "2025-12-11T08:03:57.314906",
     "exception": false,
     "start_time": "2025-12-11T08:03:57.293001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ“ˆ K-MEANS EVALUATION METRICS\n",
      "================================================================================\n",
      "\n",
      "Metrics Comparison (normalized 0-1):\n",
      " K  Inertia_Norm  Silhouette_Norm\n",
      "20      1.000000         0.000000\n",
      "40      0.288986         0.643186\n",
      "60      0.867579         0.117665\n",
      "80      0.000000         1.000000\n",
      "\n",
      "ðŸ† Best by Silhouette Score: K=80\n",
      "ðŸ† Best by Inertia (Elbow): K=80\n",
      "\n",
      "ðŸ’¡ Recommendation: Check cluster quality manually and select K based on semantic coherence.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“ˆ K-MEANS EVALUATION METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize metrics for comparison\n",
    "tuning_df['Inertia_Norm'] = (tuning_df['Inertia'] - tuning_df['Inertia'].min()) / (tuning_df['Inertia'].max() - tuning_df['Inertia'].min())\n",
    "tuning_df['Silhouette_Norm'] = (tuning_df['Silhouette'] - tuning_df['Silhouette'].min()) / (tuning_df['Silhouette'].max() - tuning_df['Silhouette'].min())\n",
    "\n",
    "print(\"\\nMetrics Comparison (normalized 0-1):\")\n",
    "print(tuning_df[['K', 'Inertia_Norm', 'Silhouette_Norm']].to_string(index=False))\n",
    "\n",
    "# Find best K by each metric\n",
    "best_by_silhouette = tuning_df.loc[tuning_df['Silhouette'].idxmax(), 'K']\n",
    "best_by_inertia = tuning_df.loc[tuning_df['Inertia'].idxmin(), 'K']\n",
    "\n",
    "print(f\"\\nðŸ† Best by Silhouette Score: K={int(best_by_silhouette)}\")\n",
    "print(f\"ðŸ† Best by Inertia (Elbow): K={int(best_by_inertia)}\")\n",
    "print(f\"\\nðŸ’¡ Recommendation: Check cluster quality manually and select K based on semantic coherence.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3447756e",
   "metadata": {
    "papermill": {
     "duration": 0.004494,
     "end_time": "2025-12-11T08:03:57.324592",
     "exception": false,
     "start_time": "2025-12-11T08:03:57.320098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 5: Inspect Cluster Quality by Job Titles and Skills\n",
    "\n",
    "For each K value, inspect representative clusters to assess semantic coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60fa3c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T08:03:57.335750Z",
     "iopub.status.busy": "2025-12-11T08:03:57.335402Z",
     "iopub.status.idle": "2025-12-11T08:03:58.625763Z",
     "shell.execute_reply": "2025-12-11T08:03:58.624656Z"
    },
    "papermill": {
     "duration": 1.298617,
     "end_time": "2025-12-11T08:03:58.627669",
     "exception": false,
     "start_time": "2025-12-11T08:03:57.329052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CLUSTER INSPECTION: K=20\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Cluster Size Distribution:\n",
      "  Min:     1 jobs\n",
      "  Max: 2452415 jobs\n",
      "  Mean: 144228 jobs\n",
      "  Std: 550181\n",
      "\n",
      "ðŸ” Cluster 12 (31 jobs)\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Top 10 Job Titles:\n",
      "    â€¢ Mental Health Counselor                            (  2 occurrences)\n",
      "    â€¢ Permanent Charge Nurse (RN) - Acute Care of the Elderly, ACE Unit (  1 occurrences)\n",
      "    â€¢ SpÃ©cialiste en activitÃ©s cliniques                 (  1 occurrences)\n",
      "    â€¢ Social Work Care Manager                           (  1 occurrences)\n",
      "    â€¢ Senior Manager, Product Manager, Innovation Lab    (  1 occurrences)\n",
      "    â€¢ Registered Nurse (I, II, III, or IV), Acute Care - Inpatient Pediatric Unit at Bassett Healthcare (  1 occurrences)\n",
      "    â€¢ Registered Nurse -(All vacancies including PRN, PT, FT) at Veterans Affairs, Veterans Health Administration (  1 occurrences)\n",
      "    â€¢ Program Supervisor                                 (  1 occurrences)\n",
      "    â€¢ Mental Health Therapist - Outpatient Care Services SPA 5 (  1 occurrences)\n",
      "    â€¢ Mental Health Counselor/Therapist                  (  1 occurrences)\n",
      "\n",
      "  Top 20 Most Frequent Skills:\n",
      "    â€¢ teamwork                                   65 jobs (209.7%)\n",
      "    â€¢ communication                              65 jobs (209.7%)\n",
      "    â€¢ leadership                                 65 jobs (209.7%)\n",
      "    â€¢ problem solving                            60 jobs (193.5%)\n",
      "    â€¢ time management                            50 jobs (161.3%)\n",
      "    â€¢ ethics                                     44 jobs (141.9%)\n",
      "    â€¢ crisis intervention                        36 jobs (116.1%)\n",
      "    â€¢ conflict resolution                        36 jobs (116.1%)\n",
      "    â€¢ critical thinking                          33 jobs (106.5%)\n",
      "    â€¢ cultural competence                        33 jobs (106.5%)\n",
      "    â€¢ collaboration                              33 jobs (106.5%)\n",
      "    â€¢ decision making                            32 jobs (103.2%)\n",
      "    â€¢ advocacy                                   31 jobs (100.0%)\n",
      "    â€¢ counseling                                 28 jobs ( 90.3%)\n",
      "    â€¢ case management                            27 jobs ( 87.1%)\n",
      "    â€¢ documentation                              26 jobs ( 83.9%)\n",
      "    â€¢ research                                   24 jobs ( 77.4%)\n",
      "    â€¢ professionalism                            23 jobs ( 74.2%)\n",
      "    â€¢ empathy                                    22 jobs ( 71.0%)\n",
      "    â€¢ mental health                              22 jobs ( 71.0%)\n",
      "\n",
      "  Skill Categories:\n",
      "    â€¢ other,soft skills,specialized industry skills: 25 jobs\n",
      "    â€¢ other,soft skills: 3 jobs\n",
      "    â€¢ other,soft skills,specialized industry skills,tech skills: 2 jobs\n",
      "    â€¢ business skills,disruptive tech skills,other,soft skills,specialized industry skills: 1 jobs\n",
      "\n",
      "ðŸ” Cluster 16 (6 jobs)\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Top 10 Job Titles:\n",
      "    â€¢ Specialist Nurse - Haemoglobinopathy - Maternity Cover (  1 occurrences)\n",
      "    â€¢ Advanced Practice Provider (NP or PA) - Cardiac ICU - PALS (  1 occurrences)\n",
      "    â€¢ Medical Technologist                               (  1 occurrences)\n",
      "    â€¢ Nurse Practitioner, Inpatient Oncology             (  1 occurrences)\n",
      "    â€¢ Nurse Practitioner or Physician Assistant, Inpatient GI (  1 occurrences)\n",
      "    â€¢ Nurse Practitioner, Outpatient Oncology            (  1 occurrences)\n",
      "\n",
      "  Top 20 Most Frequent Skills:\n",
      "    â€¢ family                                     18 jobs (300.0%)\n",
      "    â€¢ telemedicine                                7 jobs (116.7%)\n",
      "    â€¢ oncology                                    7 jobs (116.7%)\n",
      "    â€¢ patient                                     6 jobs (100.0%)\n",
      "    â€¢ caregiver                                   6 jobs (100.0%)\n",
      "    â€¢ cardiology                                  6 jobs (100.0%)\n",
      "    â€¢ orthopedics                                 6 jobs (100.0%)\n",
      "    â€¢ cancer care                                 6 jobs (100.0%)\n",
      "    â€¢ 401(k) plan                                 6 jobs (100.0%)\n",
      "    â€¢ employee stock purchase plan                6 jobs (100.0%)\n",
      "    â€¢ paid time off                               6 jobs (100.0%)\n",
      "    â€¢ paid family leave                           6 jobs (100.0%)\n",
      "    â€¢ longterm disability coverage                6 jobs (100.0%)\n",
      "    â€¢ healthcare                                  6 jobs (100.0%)\n",
      "    â€¢ shortterm disability coverage               5 jobs ( 83.3%)\n",
      "    â€¢ leaves of absence                           5 jobs ( 83.3%)\n",
      "    â€¢ employee health assistance fund             5 jobs ( 83.3%)\n",
      "    â€¢ tuition assistance                          5 jobs ( 83.3%)\n",
      "    â€¢ student loan assistance                     5 jobs ( 83.3%)\n",
      "    â€¢ certification support                       5 jobs ( 83.3%)\n",
      "\n",
      "  Skill Categories:\n",
      "    â€¢ other,specialized industry skills: 3 jobs\n",
      "    â€¢ other: 2 jobs\n",
      "    â€¢ other,soft skills,specialized industry skills: 1 jobs\n",
      "\n",
      "================================================================================\n",
      "CLUSTER INSPECTION: K=40\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Cluster Size Distribution:\n",
      "  Min:     5 jobs\n",
      "  Max: 856670 jobs\n",
      "  Mean: 75909 jobs\n",
      "  Std: 159753\n",
      "\n",
      "ðŸ” Cluster 6 (10251 jobs)\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Top 10 Job Titles:\n",
      "    â€¢ Software Tester                                    (10251 occurrences)\n",
      "\n",
      "  Top 20 Most Frequent Skills:\n",
      "    â€¢ quality assurance processes testing methodologies (e.g. 10251 jobs (100.0%)\n",
      "    â€¢ manual                                   10251 jobs (100.0%)\n",
      "    â€¢ automated) bug tracking and reporting test case development regression testing 10251 jobs (100.0%)\n",
      "\n",
      "  Skill Categories:\n",
      "    â€¢ other: 10251 jobs\n",
      "\n",
      "ðŸ” Cluster 7 (16710 jobs)\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Top 10 Job Titles:\n",
      "    â€¢ Network Engineer                                   (16710 occurrences)\n",
      "\n",
      "  Top 20 Most Frequent Skills:\n",
      "    â€¢ network management troubleshooting network security it certifications (e.g. 16710 jobs (100.0%)\n",
      "    â€¢ ccna)                                    16710 jobs (100.0%)\n",
      "\n",
      "  Skill Categories:\n",
      "    â€¢ other: 16710 jobs\n"
     ]
    }
   ],
   "source": [
    "def inspect_clusters(df, labels, skill_vocab, X_sparse, k, num_samples=3):\n",
    "    \"\"\"Inspect cluster quality for a given K value.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CLUSTER INSPECTION: K={k}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    df_temp = df_original.copy()\n",
    "    df_temp['cluster'] = labels\n",
    "    \n",
    "    # Get cluster sizes\n",
    "    cluster_sizes = df_temp['cluster'].value_counts().sort_index()\n",
    "    print(f\"\\nðŸ“Š Cluster Size Distribution:\")\n",
    "    print(f\"  Min: {cluster_sizes.min():5d} jobs\")\n",
    "    print(f\"  Max: {cluster_sizes.max():5d} jobs\")\n",
    "    print(f\"  Mean: {cluster_sizes.mean():5.0f} jobs\")\n",
    "    print(f\"  Std: {cluster_sizes.std():5.0f}\")\n",
    "    \n",
    "    # Sample clusters to inspect\n",
    "    sampled_clusters = np.random.choice(k, num_samples, replace=False)\n",
    "    \n",
    "    for cluster_id in sorted(sampled_clusters):\n",
    "        cluster_jobs = df_temp[df_temp['cluster'] == cluster_id]\n",
    "        cluster_mask = (df_temp['cluster'] == cluster_id).values\n",
    "        X_cluster = X_sparse[cluster_mask]\n",
    "        \n",
    "        print(f\"\\nðŸ” Cluster {cluster_id} ({len(cluster_jobs)} jobs)\")\n",
    "        print(f\"  {'â”€'*76}\")\n",
    "        \n",
    "        # Top job titles\n",
    "        print(f\"  Top 10 Job Titles:\")\n",
    "        top_jobs = cluster_jobs['job_title'].value_counts().head(10)\n",
    "        for job, count in top_jobs.items():\n",
    "            print(f\"    â€¢ {job:50} ({count:3d} occurrences)\")\n",
    "        \n",
    "        # Top skills in this cluster\n",
    "        print(f\"\\n  Top 20 Most Frequent Skills:\")\n",
    "        cluster_skills = Counter()\n",
    "        for skills in cluster_jobs['skill_list']:\n",
    "            cluster_skills.update(skills)\n",
    "        \n",
    "        for skill, count in cluster_skills.most_common(20):\n",
    "            pct = (count / len(cluster_jobs)) * 100\n",
    "            print(f\"    â€¢ {skill:40} {count:4d} jobs ({pct:5.1f}%)\")\n",
    "        \n",
    "        # Dominant skill categories (if available)\n",
    "        if 'skill_categories' in df_temp.columns:\n",
    "            print(f\"\\n  Skill Categories:\")\n",
    "            cats = cluster_jobs['skill_categories'].fillna('').value_counts().head(5)\n",
    "            for cat, count in cats.items():\n",
    "                if cat:\n",
    "                    print(f\"    â€¢ {cat}: {count} jobs\")\n",
    "\n",
    "# Inspect clusters for a few K values to assess quality\n",
    "for result in tuning_results[:2]:  # Inspect K=20 and K=40 for now\n",
    "    k = result['K']\n",
    "    labels = result['Labels']\n",
    "    inspect_clusters(df_original, labels, skill_vocab, X_sparse, k, num_samples=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579d6f49",
   "metadata": {
    "papermill": {
     "duration": 0.004804,
     "end_time": "2025-12-11T08:03:58.637881",
     "exception": false,
     "start_time": "2025-12-11T08:03:58.633077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 6: Select Optimal K and Re-fit Model\n",
    "\n",
    "Based on silhouette scores, inertia, and manual inspection, select the best K and train final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce958c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T08:03:58.649072Z",
     "iopub.status.busy": "2025-12-11T08:03:58.648713Z",
     "iopub.status.idle": "2025-12-11T08:03:58.757356Z",
     "shell.execute_reply": "2025-12-11T08:03:58.756261Z"
    },
    "papermill": {
     "duration": 0.11635,
     "end_time": "2025-12-11T08:03:58.758989",
     "exception": false,
     "start_time": "2025-12-11T08:03:58.642639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "âœ… SELECTED OPTIMAL K = 40\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Final Cluster Distribution (K=40):\n",
      "  Clusters: 38\n",
      "  Min cluster size: 5\n",
      "  Max cluster size: 856670\n",
      "  Mean cluster size: 75909\n",
      "  Std cluster size: 157637\n",
      "\n",
      "âœ… Cluster assignments added to dataframe\n"
     ]
    }
   ],
   "source": [
    "# SELECT OPTIMAL K\n",
    "# Based on silhouette score and manual inspection, select the best K\n",
    "# You can adjust this based on your inspection results above\n",
    "\n",
    "optimal_k = 40  # Adjust based on silhouette score and cluster quality inspection\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"âœ… SELECTED OPTIMAL K = {optimal_k}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get the model with optimal K\n",
    "optimal_result = next(r for r in tuning_results if r['K'] == optimal_k)\n",
    "optimal_kmeans = optimal_result['Model']\n",
    "optimal_labels = optimal_result['Labels']\n",
    "\n",
    "# Verify cluster distribution\n",
    "unique, counts = np.unique(optimal_labels, return_counts=True)\n",
    "print(f\"\\nðŸ“Š Final Cluster Distribution (K={optimal_k}):\")\n",
    "print(f\"  Clusters: {len(unique)}\")\n",
    "print(f\"  Min cluster size: {counts.min()}\")\n",
    "print(f\"  Max cluster size: {counts.max()}\")\n",
    "print(f\"  Mean cluster size: {counts.mean():.0f}\")\n",
    "print(f\"  Std cluster size: {counts.std():.0f}\")\n",
    "\n",
    "# Add cluster labels to the original dataframe\n",
    "df_original['cluster_id'] = optimal_labels\n",
    "\n",
    "print(f\"\\nâœ… Cluster assignments added to dataframe\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a4b7db",
   "metadata": {
    "papermill": {
     "duration": 0.004911,
     "end_time": "2025-12-11T08:03:58.769073",
     "exception": false,
     "start_time": "2025-12-11T08:03:58.764162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 7: Create Compact Cluster Mapping\n",
    "\n",
    "Create a lightweight mapping file with job_id, title, company, location, cluster_id, and main_category for the Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77ad01f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T08:03:58.780543Z",
     "iopub.status.busy": "2025-12-11T08:03:58.780215Z",
     "iopub.status.idle": "2025-12-11T08:04:17.725346Z",
     "shell.execute_reply": "2025-12-11T08:04:17.723864Z"
    },
    "papermill": {
     "duration": 18.953057,
     "end_time": "2025-12-11T08:04:17.727074",
     "exception": false,
     "start_time": "2025-12-11T08:03:58.774017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ“¦ CREATING COMPACT CLUSTER MAPPING\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Compact Mapping Shape: (2884556, 6)\n",
      "ðŸ“‹ Columns: ['job_id', 'job_title', 'company', 'location', 'cluster_id', 'main_category']\n",
      "\n",
      "ðŸŽ¯ Sample Records:\n",
      "                                                                                                                job_id                               job_title                                 company                                             location  cluster_id   main_category\n",
      "                  https://ae.linkedin.com/jobs/view/bar-supervisor-saadiyat-beach-club-at-aldar-hospitality-3795826819    Bar Supervisor - Saadiyat Beach Club                       Aldar Hospitality   Abu Dhabi, Abu Dhabi Emirate, United Arab Emirates          24           other\n",
      "                       https://ae.linkedin.com/jobs/view/duty-engineer-at-arjaan-hotel-apartments-by-rotana-3801219786                           Duty Engineer       Arjaan Hotel Apartments by Rotana              Abu Dhabi Emirate, United Arab Emirates          24           other\n",
      "                             https://ae.linkedin.com/jobs/view/eau-fire-life-safety-engineer-m-f-at-socotec-3690236750 EAU - Fire & Life Safety Engineer (M/F)                                 SOCOTEC   Abu Dhabi, Abu Dhabi Emirate, United Arab Emirates          37           other\n",
      "                             https://ae.linkedin.com/jobs/view/electrician-at-m%C3%B6venpick-hotels-resorts-3784881742                             Electrician              MÃ¶venpick Hotels & Resorts                   Dubai, Dubai, United Arab Emirates           1           other\n",
      "       https://ae.linkedin.com/jobs/view/entertainment-manager-f-b-at-apt-resources-recruitment-specialists-3776713356             Entertainment Manager - F&B Apt Resources | Recruitment Specialists   Abu Dhabi, Abu Dhabi Emirate, United Arab Emirates           1           other\n",
      "    https://ae.linkedin.com/jobs/view/evs-operator-at-sundus-recruitment-and-outsourcing-services-abu-dhabi-3772971736                            EVS Operator                                  Sundus   Abu Dhabi, Abu Dhabi Emirate, United Arab Emirates          24           other\n",
      "                            https://ae.linkedin.com/jobs/view/housing-attendant-at-all-accor-live-limitless-3786651185                       Housing Attendant              ALL - Accor Live Limitless Ras Al Khaimah, Ras al-Khaimah, United Arab Emirates           1           other\n",
      "                                     https://ae.linkedin.com/jobs/view/internal-auditor-at-burjeel-holdings-3794125638                        Internal Auditor                        Burjeel Holdings   Abu Dhabi, Abu Dhabi Emirate, United Arab Emirates          24 business skills\n",
      "                                  https://ae.linkedin.com/jobs/view/internal-auditor-at-dubai-holding-group-3799015219                        Internal Auditor                     Dubai Holding Group                          Dubai, United Arab Emirates          13 business skills\n",
      "https://ae.linkedin.com/jobs/view/machine-operator-at-sundus-recruitment-and-outsourcing-services-abu-dhabi-3758264065                        Machine Operator                                  Sundus                                 United Arab Emirates           1           other\n",
      "\n",
      "âœ… Saved: /kaggle/working/job_clusters_small_v2.pkl\n",
      "âœ… Saved: /kaggle/working/job_clusters_small_v2.csv\n",
      "\n",
      "ðŸ’¾ File Sizes:\n",
      "  Pickle: 255.48 MB\n",
      "  CSV: 336.47 MB\n"
     ]
    }
   ],
   "source": [
    "# Function to extract dominant skill category per job\n",
    "def get_main_category(skill_categories_str):\n",
    "    \"\"\"Extract primary skill category from the concatenated string.\"\"\"\n",
    "    if pd.isna(skill_categories_str) or not skill_categories_str:\n",
    "        return 'other'\n",
    "    categories = str(skill_categories_str).split(',')\n",
    "    return categories[0].strip() if categories else 'other'\n",
    "\n",
    "# Build compact mapping\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“¦ CREATING COMPACT CLUSTER MAPPING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# df_original contains job_id thanks to Section 1\n",
    "cluster_mapping = df_original[[\n",
    "    'job_id', 'job_title', 'company', 'location', 'cluster_id'\n",
    "]].copy()\n",
    "\n",
    "cluster_mapping['main_category'] = df_original['skill_categories'].apply(get_main_category)\n",
    "\n",
    "print(f\"\\nðŸ“Š Compact Mapping Shape: {cluster_mapping.shape}\")\n",
    "print(f\"ðŸ“‹ Columns: {list(cluster_mapping.columns)}\")\n",
    "print(f\"\\nðŸŽ¯ Sample Records:\")\n",
    "print(cluster_mapping.head(10).to_string(index=False))\n",
    "\n",
    "# Save as pickle (more efficient than CSV for repeated loading)\n",
    "output_path = \"/kaggle/working/job_clusters_small_v2.pkl\"\n",
    "cluster_mapping.to_pickle(output_path)\n",
    "print(f\"\\nâœ… Saved: {output_path}\")\n",
    "\n",
    "# Also save as CSV for debugging/inspection\n",
    "csv_path = output_path.replace('.pkl', '.csv')\n",
    "cluster_mapping.to_csv(csv_path, index=False)\n",
    "print(f\"âœ… Saved: {csv_path}\")\n",
    "\n",
    "# File size comparison\n",
    "import os\n",
    "pkl_size = os.path.getsize(output_path) / 1024 / 1024\n",
    "csv_size = os.path.getsize(csv_path) / 1024 / 1024\n",
    "print(f\"\\nðŸ’¾ File Sizes:\")\n",
    "print(f\"  Pickle: {pkl_size:.2f} MB\")\n",
    "print(f\"  CSV: {csv_size:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d81f2c",
   "metadata": {
    "papermill": {
     "duration": 0.005147,
     "end_time": "2025-12-11T08:04:17.737638",
     "exception": false,
     "start_time": "2025-12-11T08:04:17.732491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 8: Implement Post-Filter Logic for Similar Jobs\n",
    "\n",
    "Define helper functions to extract dominant skills and filter similar jobs by skill overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc8de956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T08:04:17.750842Z",
     "iopub.status.busy": "2025-12-11T08:04:17.750505Z",
     "iopub.status.idle": "2025-12-11T08:04:36.896475Z",
     "shell.execute_reply": "2025-12-11T08:04:36.895480Z"
    },
    "papermill": {
     "duration": 19.155025,
     "end_time": "2025-12-11T08:04:36.897893",
     "exception": false,
     "start_time": "2025-12-11T08:04:17.742868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ”§ SKILL-BASED FILTERING LOGIC\n",
      "================================================================================\n",
      "\n",
      "âœ… Filtering functions created\n",
      "\n",
      "ðŸ’¡ Filtering Strategy:\n",
      "   1. Find jobs in same cluster\n",
      "   2. Filter by >= 1 overlapping key skill\n",
      "   3. Fallback to unfiltered cluster if needed (marked as 'loose_match')\n",
      "\n",
      "ðŸ§ª TEST: Filtering similar jobs for 'Associate Nurse Unit Manager - Custodial FYMHS'\n",
      "   Job ID: https://au.linkedin.com/jobs/view/%09associate-nurse-unit-manager-custodial-fymhs-at-the-royal-melbourne-hospital-3803879583\n",
      "   Cluster: 34\n",
      "\n",
      "   Original cluster size: 213959\n",
      "   After filtering: 1158\n",
      "   Match quality: high_quality\n",
      "\n",
      "   Filtered sample jobs:\n",
      "     â€¢ Audit Senior\n",
      "     â€¢ Case Manager\n",
      "     â€¢ Case Manager\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ”§ SKILL-BASED FILTERING LOGIC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Extract dominant skills per job for filtering\n",
    "def get_top_skills(skill_list, n_top=5):\n",
    "    \"\"\"Get top N most common skills.\"\"\"\n",
    "    return skill_list[:n_top] if skill_list else []\n",
    "\n",
    "# Create a skills lookup table for filtering\n",
    "skills_lookup = pd.DataFrame({\n",
    "    'job_id': df_original['job_id'],\n",
    "    'top_skills': df_original['skill_list'].apply(lambda x: get_top_skills(x, n_top=5)),\n",
    "    'skill_categories': df_original['skill_categories'],\n",
    "    'location': df_original['location'],\n",
    "    'cluster_id': df_original['cluster_id']\n",
    "})\n",
    "\n",
    "def get_skill_overlap(skills_a, skills_b):\n",
    "    \"\"\"Compute skill overlap between two job skill lists.\"\"\"\n",
    "    set_a = set(skills_a)\n",
    "    set_b = set(skills_b)\n",
    "    overlap = set_a & set_b\n",
    "    return len(overlap), overlap\n",
    "\n",
    "def filter_similar_jobs(target_job_id, cluster_jobs_df, df_with_skills, min_skill_overlap=1):\n",
    "    \"\"\"\n",
    "    Filter similar jobs based on:\n",
    "    1. Same cluster\n",
    "    2. At least min_skill_overlap skills in common\n",
    "    3. Optional: same skill category\n",
    "\n",
    "    Returns: filtered DataFrame and match_quality flag\n",
    "    \"\"\"\n",
    "    # Get target job skills\n",
    "    target_job = df_with_skills[df_with_skills['job_id'] == str(target_job_id)]\n",
    "    if target_job.empty:\n",
    "        return pd.DataFrame(), 'not_found'\n",
    "\n",
    "    target_skills = target_job.iloc[0]['top_skills']\n",
    "    target_category = target_job.iloc[0]['skill_categories']\n",
    "\n",
    "    # Filter candidates by skill overlap\n",
    "    filtered = []\n",
    "    for _, candidate in cluster_jobs_df.iterrows():\n",
    "        if candidate['job_id'] == str(target_job_id):\n",
    "            continue  # Skip the target job itself\n",
    "\n",
    "        candidate_skills = candidate['top_skills']\n",
    "        overlap, _ = get_skill_overlap(target_skills, candidate_skills)\n",
    "\n",
    "        if overlap >= min_skill_overlap:\n",
    "            filtered.append(candidate)\n",
    "\n",
    "    if filtered:\n",
    "        return pd.DataFrame(filtered), 'high_quality'\n",
    "    else:\n",
    "        # Fallback: return unfiltered cluster jobs (loose match)\n",
    "        return cluster_jobs_df[cluster_jobs_df['job_id'] != str(target_job_id)], 'loose_match'\n",
    "\n",
    "print(\"\\nâœ… Filtering functions created\")\n",
    "print(\"\\nðŸ’¡ Filtering Strategy:\")\n",
    "print(\"   1. Find jobs in same cluster\")\n",
    "print(\"   2. Filter by >= 1 overlapping key skill\")\n",
    "print(\"   3. Fallback to unfiltered cluster if needed (marked as 'loose_match')\")\n",
    "\n",
    "# Test filtering with a sample nursing job\n",
    "sample_nursing = df_original[df_original['job_title'].str.contains('nurse', case=False, na=False)]\n",
    "if not sample_nursing.empty:\n",
    "    test_job_id = sample_nursing.iloc[0]['job_id']\n",
    "    test_job_title = sample_nursing.iloc[0]['job_title']\n",
    "    test_cluster = sample_nursing.iloc[0]['cluster_id']\n",
    "\n",
    "    print(f\"\\nðŸ§ª TEST: Filtering similar jobs for '{test_job_title}'\")\n",
    "    print(f\"   Job ID: {test_job_id}\")\n",
    "    print(f\"   Cluster: {test_cluster}\")\n",
    "\n",
    "    # Get cluster jobs\n",
    "    cluster_jobs = skills_lookup[skills_lookup['cluster_id'] == test_cluster]\n",
    "\n",
    "    # Apply filtering\n",
    "    filtered_jobs, match_quality = filter_similar_jobs(\n",
    "        test_job_id,\n",
    "        cluster_jobs,\n",
    "        skills_lookup,\n",
    "        min_skill_overlap=1\n",
    "    )\n",
    "\n",
    "    print(f\"\\n   Original cluster size: {len(cluster_jobs)}\")\n",
    "    print(f\"   After filtering: {len(filtered_jobs)}\")\n",
    "    print(f\"   Match quality: {match_quality}\")\n",
    "\n",
    "    if not filtered_jobs.empty:\n",
    "        print(f\"\\n   Filtered sample jobs:\")\n",
    "        for idx, job in filtered_jobs.head(3).iterrows():\n",
    "            match_row = cluster_mapping[cluster_mapping['job_id'] == job['job_id']]\n",
    "            title = match_row['job_title'].values[0] if not match_row.empty else 'Unknown'\n",
    "            print(f\"     â€¢ {title}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0eb815",
   "metadata": {
    "papermill": {
     "duration": 0.005726,
     "end_time": "2025-12-11T08:04:36.909332",
     "exception": false,
     "start_time": "2025-12-11T08:04:36.903606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Section 9: Export Results and Save for App Integration\n",
    "\n",
    "Save the fitted K-Means model, cluster mapping, and skills lookup for use in the Streamlit app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83070546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T08:04:36.922515Z",
     "iopub.status.busy": "2025-12-11T08:04:36.922121Z",
     "iopub.status.idle": "2025-12-11T08:04:44.625134Z",
     "shell.execute_reply": "2025-12-11T08:04:44.624014Z"
    },
    "papermill": {
     "duration": 7.711964,
     "end_time": "2025-12-11T08:04:44.626779",
     "exception": false,
     "start_time": "2025-12-11T08:04:36.914815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ’¾ SAVING RESULTS FOR STREAMLIT APP\n",
      "================================================================================\n",
      "âœ… K-Means model: /kaggle/working/kmeans_model_v2.pkl\n",
      "âœ… Cluster mapping: ../data/processed/job_clusters_small_v2.pkl\n",
      "âœ… Skills lookup: /kaggle/working/skills_lookup_v2.pkl\n",
      "\n",
      "âœ… Filtering logic ready for src/models/cluster_analyzer.py\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š FINAL SUMMARY\n",
      "================================================================================\n",
      "  Total jobs clustered: 2884556\n",
      "  Number of clusters (K): 40\n",
      "  Avg jobs per cluster: 72114\n",
      "  Skill vocabulary size: 61954\n",
      "  Feature matrix: (2884556, 61954)\n",
      "\n",
      "  Saved Files:\n",
      "    â€¢ job_clusters_small_v2.pkl (cluster mapping)\n",
      "    â€¢ job_clusters_small_v2.csv (for inspection)\n",
      "    â€¢ kmeans_model_v2.pkl (fitted model)\n",
      "    â€¢ skills_lookup_v2.pkl (for filtering)\n",
      "\n",
      "âœ… CLUSTERING PIPELINE COMPLETE!\n",
      "   Next: Update src/models/cluster_analyzer.py to load v2 files\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ’¾ SAVING RESULTS FOR STREAMLIT APP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Save the fitted K-Means model\n",
    "kmeans_model_path = \"/kaggle/working/kmeans_model_v2.pkl\"\n",
    "joblib.dump({\n",
    "    'model': optimal_kmeans,\n",
    "    'n_clusters': optimal_k,\n",
    "    'skill_vocab': skill_vocab,\n",
    "    'skill_to_idx': {skill: idx for idx, skill in enumerate(skill_vocab)},\n",
    "    'min_freq': min_freq,\n",
    "}, kmeans_model_path)\n",
    "print(f\"âœ… K-Means model: {kmeans_model_path}\")\n",
    "\n",
    "# 2. Save the cluster mapping (already saved earlier)\n",
    "print(f\"âœ… Cluster mapping: ../data/processed/job_clusters_small_v2.pkl\")\n",
    "\n",
    "# 3. Save skills lookup for filtering\n",
    "skills_lookup_path = \"/kaggle/working/skills_lookup_v2.pkl\"\n",
    "skills_lookup.to_pickle(skills_lookup_path)\n",
    "print(f\"âœ… Skills lookup: {skills_lookup_path}\")\n",
    "\n",
    "# 4. Save filtering functions as a module reference\n",
    "print(f\"\\nâœ… Filtering logic ready for src/models/cluster_analyzer.py\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"ðŸ“Š FINAL SUMMARY\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"  Total jobs clustered: {len(cluster_mapping)}\")\n",
    "print(f\"  Number of clusters (K): {optimal_k}\")\n",
    "print(f\"  Avg jobs per cluster: {len(cluster_mapping) / optimal_k:.0f}\")\n",
    "print(f\"  Skill vocabulary size: {len(skill_vocab)}\")\n",
    "print(f\"  Feature matrix: {X_sparse.shape}\")\n",
    "print(f\"\\n  Saved Files:\")\n",
    "print(f\"    â€¢ job_clusters_small_v2.pkl (cluster mapping)\")\n",
    "print(f\"    â€¢ job_clusters_small_v2.csv (for inspection)\")\n",
    "print(f\"    â€¢ kmeans_model_v2.pkl (fitted model)\")\n",
    "print(f\"    â€¢ skills_lookup_v2.pkl (for filtering)\")\n",
    "print(f\"\\nâœ… CLUSTERING PIPELINE COMPLETE!\")\n",
    "print(f\"   Next: Update src/models/cluster_analyzer.py to load v2 files\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8879404,
     "sourceId": 14015965,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 363.687303,
   "end_time": "2025-12-11T08:04:48.055400",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-11T07:58:44.368097",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
