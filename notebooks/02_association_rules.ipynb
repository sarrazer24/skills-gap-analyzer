{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14015965,"sourceType":"datasetVersion","datasetId":8879404}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":1640.72169,"end_time":"2025-12-05T22:49:04.622943","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-12-05T22:21:43.901253","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sarraverse/02-association-rules?scriptVersionId=284547284\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"id":"2b74a875","cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/sarraverse/02-association-rules?scriptVersionId=284161070\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"id":"5b321591","cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-12-07T19:23:29.461442Z","iopub.execute_input":"2025-12-07T19:23:29.461861Z","iopub.status.idle":"2025-12-07T19:23:31.092868Z","shell.execute_reply.started":"2025-12-07T19:23:29.461834Z","shell.execute_reply":"2025-12-07T19:23:31.09207Z"},"papermill":{"duration":1.724677,"end_time":"2025-12-05T22:21:50.056028","exception":false,"start_time":"2025-12-05T22:21:48.331351","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/job-skills/skill_migration_public.csv\n/kaggle/input/job-skills/all_jobs_clustered_full.csv\n/kaggle/input/job-skills/association_rules_categories.csv\n/kaggle/input/job-skills/all_jobs_mapped.csv\n/kaggle/input/job-skills/all_jobs_clustered_sample_dbscan.csv\n/kaggle/input/job-skills/association_rules_combined.csv\n/kaggle/input/job-skills/all_jobs_clean_full.csv\n/kaggle/input/job-skills/skill_migration_clean.csv\n/kaggle/input/job-skills/association_rules_skills.csv\n/kaggle/input/job-skills/all_jobs.csv\n","output_type":"stream"}],"execution_count":1},{"id":"ae8cda44","cell_type":"markdown","source":"# ASSOCIATION RULES MINING (3 MODELS)\n","metadata":{"papermill":{"duration":0.001506,"end_time":"2025-12-05T22:21:50.059633","exception":false,"start_time":"2025-12-05T22:21:50.058127","status":"completed"},"tags":[]}},{"id":"848cc088","cell_type":"markdown","source":"## Model Export\n\nExport the trained models as pickle files for use in the Streamlit application. **Model A2 (category-level) is used for skill recommendations in the app.**","metadata":{}},{"id":"5dde1410","cell_type":"code","source":"import pandas as pd\nimport re\nimport ast\nfrom collections import Counter\nfrom mlxtend.preprocessing import TransactionEncoder\nfrom mlxtend.frequent_patterns import fpgrowth, apriori, association_rules\n\n# Load skills dictionary\nskills_meta = pd.read_csv(\"/kaggle/input/job-skills/skill_migration_clean.csv\")\n\nskill_dict = (\n    skills_meta[[\"skill_group_name\", \"skill_group_category\"]]\n    .drop_duplicates()\n    .set_index(\"skill_group_name\")[\"skill_group_category\"]\n    .to_dict()\n)\n\nprint(f\"Loaded {len(skill_dict)} skills.\")\n\n# Load cleaned jobs data\npath = \"/kaggle/input/job-skills/all_jobs_mapped.csv\"\ndf = pd.read_csv(path, nrows=200000)\nprint(f\"Loaded dataset shape: {df.shape}\")\n\n# Ensure skill_list is properly formatted as list\ndef to_skill_list(x):\n    if isinstance(x, list):\n        return x\n    if pd.isna(x):\n        return []\n    try:\n        val = ast.literal_eval(x)\n        if isinstance(val, list):\n            return [str(s).strip().lower() for s in val]\n    except:\n        pass\n    return [s.strip().lower() for s in str(x).split(\",\") if s.strip()]\n\ndf[\"skill_list\"] = df[\"skill_list\"].apply(to_skill_list)\ndf[\"skill_categories\"] = df[\"skill_categories\"].fillna(\"\").astype(str)\n\n# Define helper functions for parsing skills\ndef parse_skills(raw):\n    if pd.isna(raw):\n        return []\n    text = str(raw).strip().lower()\n    if not text:\n        return []\n    parts = re.split(r\",|/|;|\\||\\+\", text)\n    return [p.strip() for p in parts if p.strip()]\n\ndef map_skill_categories(skill_list):\n    cats = set()\n    for s in skill_list:\n        cat = skill_dict.get(s)\n        if cat is None:\n            cat = \"other\"\n        cats.add(cat)\n    if not cats:\n        return \"\"\n    return \",\".join(sorted(cats))\n\ndef cat_list(cats_str):\n    if not cats_str:\n        return []\n    return [c.strip().lower() for c in cats_str.split(\",\") if c.strip()]\n\n# Prepare transactions for all models\nprint(\"\\nPreparing transaction data...\")\n\n# Model A1: skills only\ntransactions_skills = df[\"skill_list\"].tolist()\nprint(f\"Model A1: {len(transactions_skills)} transactions with skills\")\n\n# Model A2: categories only\ndf[\"cat_list\"] = df[\"skill_categories\"].apply(cat_list)\ntransactions_cats = df[\"cat_list\"].tolist()\nprint(f\"Model A2: {len(transactions_cats)} transactions with categories\")\n\n# Model A3: skills + categories\ndef combined_list(row):\n    return row[\"skill_list\"] + row[\"cat_list\"]\n\ndf[\"combined_list\"] = df.apply(combined_list, axis=1)\ntransactions_combined = df[\"combined_list\"].tolist()\nprint(f\"Model A3: {len(transactions_combined)} transactions with skills + categories\")\n\n# Model A1: FP-Growth with skill-level rules\nprint(\"\\n=== Running Model A1: Skill-Level Association Rules ===\")\nn_transactions = len(transactions_skills)\nmin_support = 0.01\nmin_confidence = 0.4\nmin_occurrences = 10\n\nmin_occ_from_support = max(1, int(min_support * n_transactions))\nmin_keep = max(min_occurrences, min_occ_from_support)\n\n# 1) Count skill frequencies and filter rare skills\nskill_counts = Counter(skill for tx in transactions_skills for skill in tx)\nvalid_skills = {skill for skill, cnt in skill_counts.items() if cnt >= min_keep}\nfiltered_transactions = [[s for s in tx if s in valid_skills] for tx in transactions_skills]\n\nprint(f\"Kept skills: {len(valid_skills):,} (â‰¥ {min_keep} occurrences)\")\n\n# 2) Encode transactions as a sparse matrix\nte = TransactionEncoder()\nte_ary = te.fit(filtered_transactions).transform(filtered_transactions, sparse=True)\nskills_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n\n# 3) Run FP-Growth\nfreq_itemsets_A1 = fpgrowth(skills_df, min_support=min_support, use_colnames=True)\n\n# 4) Derive association rules\nrules_A1 = association_rules(freq_itemsets_A1, metric=\"confidence\", min_threshold=min_confidence)\n\nprint(f\"âœ… Model A1: {len(rules_A1):,} rules found\")\n\n# Model A2: Category-level rules\nprint(\"\\n=== Running Model A2: Category-Level Association Rules ===\")\nte = TransactionEncoder()\nte_ary = te.fit(transactions_cats).transform(transactions_cats)\ncats_df = pd.DataFrame(te_ary, columns=te.columns_)\n\nfreq_itemsets_A2 = apriori(cats_df, min_support=0.01, use_colnames=True)\nrules_A2 = association_rules(freq_itemsets_A2, metric=\"confidence\", min_threshold=0.4)\n\nprint(f\"âœ… Model A2: {len(rules_A2):,} rules found\")\n\n# Model A3: Combined rules\nprint(\"\\n=== Running Model A3: Combined Association Rules ===\")\nn_transactions = len(transactions_combined)\nmin_support = 0.01\nmin_confidence = 0.4\nmin_occurrences = 10\n\nmin_occ_from_support = max(1, int(min_support * n_transactions))\nmin_keep = max(min_occurrences, min_occ_from_support)\n\n# 1) Filter rare categories\ncat_counts = Counter(cat for tx in transactions_combined for cat in tx)\nvalid_cats = {cat for cat, cnt in cat_counts.items() if cnt >= min_keep}\nfiltered_transactions = [[c for c in tx if c in valid_cats] for tx in transactions_combined]\n\nprint(f\"Kept categories: {len(valid_cats):,} (â‰¥ {min_keep} occurrences)\")\n\n# 2) Encode as sparse matrix\nte = TransactionEncoder()\nte_ary = te.fit(filtered_transactions).transform(filtered_transactions, sparse=True)\ncats_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n\n# 3) Use FP-Growth\nfreq_itemsets_A3 = fpgrowth(cats_df, min_support=min_support, use_colnames=True)\n\n# 4) Generate rules\nrules_A3 = association_rules(freq_itemsets_A3, metric=\"confidence\", min_threshold=min_confidence)\n\nprint(f\"âœ… Model A3: {len(rules_A3):,} rules found\")\n\n# Summary function\ndef summarize_rules(rules, name):\n    print(f\"\\n=== {name} ===\")\n    print(f\"Number of rules: {len(rules):,}\")\n    print(f\"Support range: {rules['support'].min():.4f} â†’ {rules['support'].max():.4f}\")\n    print(f\"Confidence range: {rules['confidence'].min():.4f} â†’ {rules['confidence'].max():.4f}\")\n    print(f\"Lift range: {rules['lift'].min():.4f} â†’ {rules['lift'].max():.4f}\")\n    \n    # Show top 5 rules by confidence\n    if len(rules) > 0:\n        print(\"\\nTop 5 rules by confidence:\")\n        top_rules = rules.sort_values('confidence', ascending=False).head(5)\n        for idx, row in top_rules.iterrows():\n            print(f\"  {set(row['antecedents'])} â†’ {set(row['consequents'])}\")\n            print(f\"    Support: {row['support']:.4f}, Confidence: {row['confidence']:.4f}, Lift: {row['lift']:.4f}\")\n\n# Summarize all models\nsummarize_rules(rules_A1, \"A1: skill-level\")\nsummarize_rules(rules_A2, \"A2: category-level\")\nsummarize_rules(rules_A3, \"A3: combined\")\n\n# Save results\nprint(\"\\nðŸ’¾ Saving association rules results...\")\nrules_A1.to_csv(\"/kaggle/working/association_rules_skills.csv\", index=False)\nrules_A2.to_csv(\"/kaggle/working/association_rules_categories.csv\", index=False)\nrules_A3.to_csv(\"/kaggle/working/association_rules_combined.csv\", index=False)\n\nprint(\"âœ… All association rules saved to files!\")","metadata":{"execution":{"iopub.execute_input":"2025-12-05T22:21:50.064498Z","iopub.status.busy":"2025-12-05T22:21:50.064076Z","iopub.status.idle":"2025-12-05T22:49:02.792016Z","shell.execute_reply":"2025-12-05T22:49:02.790342Z"},"papermill":{"duration":1632.734698,"end_time":"2025-12-05T22:49:02.795741","exception":false,"start_time":"2025-12-05T22:21:50.061043","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded 249 skills.\n","Loaded dataset shape: (200000, 9)\n","\n","Preparing transaction data...\n","Model A1: 200000 transactions with skills\n","Model A2: 200000 transactions with categories\n","Model A3: 200000 transactions with skills + categories\n","\n","=== Running Model A1: Skill-Level Association Rules ===\n","Kept skills: 171 (â‰¥ 2000 occurrences)\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_13/2373446715.py:108: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n","  skills_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n"]},{"name":"stdout","output_type":"stream","text":["âœ… Model A1: 308 rules found\n","\n","=== Running Model A2: Category-Level Association Rules ===\n","âœ… Model A2: 22 rules found\n","\n","=== Running Model A3: Combined Association Rules ===\n","Kept categories: 176 (â‰¥ 2000 occurrences)\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_13/2373446715.py:149: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n","  cats_df = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n"]},{"name":"stdout","output_type":"stream","text":["âœ… Model A3: 7,147 rules found\n","\n","=== A1: skill-level ===\n","Number of rules: 308\n","Support range: 0.0101 â†’ 0.1013\n","Confidence range: 0.4010 â†’ 0.9297\n","Lift range: 1.3813 â†’ 41.6524\n","\n","Top 5 rules by confidence:\n","  {'word'} â†’ {'excel'}\n","    Support: 0.0112, Confidence: 0.9297, Lift: 27.6909\n","  {'customer service', 'leadership', 'problemsolving'} â†’ {'communication'}\n","    Support: 0.0105, Confidence: 0.8965, Lift: 3.0875\n","  {'verbal communication'} â†’ {'written communication'}\n","    Support: 0.0196, Confidence: 0.8697, Lift: 35.0674\n","  {'inclusion'} â†’ {'diversity'}\n","    Support: 0.0143, Confidence: 0.8685, Lift: 41.6524\n","  {'problem solving', 'customer service', 'leadership'} â†’ {'communication'}\n","    Support: 0.0118, Confidence: 0.8664, Lift: 2.9841\n","\n","=== A2: category-level ===\n","Number of rules: 22\n","Support range: 0.0136 â†’ 0.4745\n","Confidence range: 0.4756 â†’ 1.0000\n","Lift range: 1.0017 â†’ 1.2677\n","\n","Top 5 rules by confidence:\n","  {'business skills'} â†’ {'other'}\n","    Support: 0.1904, Confidence: 1.0000, Lift: 1.0023\n","  {'soft skills', 'business skills'} â†’ {'other'}\n","    Support: 0.1118, Confidence: 1.0000, Lift: 1.0023\n","  {'soft skills', 'specialized industry skills', 'business skills'} â†’ {'other'}\n","    Support: 0.0281, Confidence: 1.0000, Lift: 1.0023\n","  {'soft skills', 'tech skills'} â†’ {'other'}\n","    Support: 0.0136, Confidence: 1.0000, Lift: 1.0023\n","  {'soft skills', 'specialized industry skills'} â†’ {'other'}\n","    Support: 0.1381, Confidence: 1.0000, Lift: 1.0023\n","\n","=== A3: combined ===\n","Number of rules: 7,147\n","Support range: 0.0100 â†’ 0.4748\n","Confidence range: 0.4010 â†’ 1.0000\n","Lift range: 0.8483 â†’ 41.6524\n","\n","Top 5 rules by confidence:\n","  {'pension scheme'} â†’ {'other'}\n","    Support: 0.0101, Confidence: 1.0000, Lift: 1.0023\n","  {'teamwork', 'communication', 'time management'} â†’ {'other'}\n","    Support: 0.0330, Confidence: 1.0000, Lift: 1.0023\n","  {'communication', 'time management', 'other', 'problemsolving'} â†’ {'soft skills'}\n","    Support: 0.0224, Confidence: 1.0000, Lift: 2.1060\n","  {'teamwork', 'time management'} â†’ {'soft skills', 'other'}\n","    Support: 0.0487, Confidence: 1.0000, Lift: 2.1062\n","  {'communication', 'time management', 'problemsolving'} â†’ {'soft skills', 'other'}\n","    Support: 0.0224, Confidence: 1.0000, Lift: 2.1062\n","\n","ðŸ’¾ Saving association rules results...\n","âœ… All association rules saved to files!\n"]}],"execution_count":2},{"id":"3f262fc2","cell_type":"code","source":"import joblib\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"ðŸ’¾ EXPORTING TRAINED MODELS FOR APPLICATION\")\nprint(\"=\" * 80)\n\n# Export Model A2 (Category-Level) - THIS IS WHAT THE APP USES\nprint(\"\\nðŸ“¦ Exporting Model A2 (Category-Level Rules)...\")\nprint(\"   â”œâ”€ This model is used for skill recommendations in the app\")\nprint(\"   â”œâ”€ It recommends related skills based on user's current skill categories\")\nprint(\"   â””â”€ Required for /app/models/association_rules.pkl\")\n\nassociation_model_a2 = {\n    'rules': rules_A2,                           # DataFrame with all association rules\n    'frequent_itemsets': freq_itemsets_A2,       # Frequent itemsets for reference\n    'model_type': 'A2_categories',               # Model identifier\n    'min_support': 0.01,                         # Parameters used\n    'min_confidence': 0.4,\n    'algorithm': 'apriori'\n}\n\njoblib.dump(association_model_a2, '/kaggle/working/association_rules_a2.pkl')\nprint(\"âœ… Saved: /kaggle/working/association_rules_a2.pkl\")\n\n# Export Model A1 (Skill-Level) - FOR REFERENCE/FUTURE USE\nprint(\"\\nðŸ“¦ Exporting Model A1 (Skill-Level Rules)...\")\nassociation_model_a1 = {\n    'rules': rules_A1,\n    'frequent_itemsets': freq_itemsets_A1,\n    'model_type': 'A1_skills',\n    'min_support': 0.01,\n    'min_confidence': 0.4,\n    'algorithm': 'fpgrowth'\n}\n\njoblib.dump(association_model_a1, '/kaggle/working/association_rules_a1.pkl')\nprint(\"âœ… Saved: /kaggle/working/association_rules_a1.pkl\")\n\n# Export Model A3 (Combined) - FOR REFERENCE/FUTURE USE\nprint(\"\\nðŸ“¦ Exporting Model A3 (Combined Rules)...\")\nassociation_model_a3 = {\n    'rules': rules_A3,\n    'frequent_itemsets': freq_itemsets_A3,\n    'model_type': 'A3_combined',\n    'min_support': 0.01,\n    'min_confidence': 0.4,\n    'algorithm': 'fpgrowth'\n}\n\njoblib.dump(association_model_a3, '/kaggle/working/association_rules_a3.pkl')\nprint(\"âœ… Saved: /kaggle/working/association_rules_a3.pkl\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"âœ… MODEL EXPORT COMPLETE\")\nprint(\"=\" * 80)\nprint(\"\\nðŸ“‹ Summary:\")\nprint(f\"  â€¢ Model A2 Rules: {len(rules_A2):,} rules\")\nprint(f\"  â€¢ Model A2 Quality: Avg Confidence={rules_A2['confidence'].mean():.1%}, Avg Lift={rules_A2['lift'].mean():.2f}\")\nprint(\"\\nðŸ’¡ Next Step:\")\nprint(\"  1. Download association_rules_a2.pkl from Kaggle\")\nprint(\"  2. Place in: app/models/association_rules.pkl\")\nprint(\"  3. The app will use this for generating skill recommendations\")","metadata":{},"outputs":[],"execution_count":null}]}